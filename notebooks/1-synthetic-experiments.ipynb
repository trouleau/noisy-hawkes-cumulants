{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libs\n",
    "from pprint import pprint\n",
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from tick.hawkes.simulation import SimuHawkesExpKernels\n",
    "# lib for: ADM4, NPHC, WH\n",
    "from tick.hawkes.inference import HawkesConditionalLaw, HawkesADM4, HawkesCumulantMatching\n",
    "from tick.dataset import fetch_hawkes_bund_data\n",
    "# lib for: Desync-MLE \n",
    "from desync_mhp.lib.inference import HawkesExpKernConditionalMLE\n",
    "\n",
    "# Internal lib\n",
    "import lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Define model and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ground-truth parameters\n",
    "adjacency = np.array([ [0.23, 0.23, 0.23, 0.23, 0.23, 0.  , 0.  , 0.  , 0.  , 0.23],\n",
    "                       [0.  , 0.23, 0.23, 0.23, 0.23, 0.  , 0.  , 0.  , 0.23, 0.  ],\n",
    "                       [0.  , 0.  , 0.23, 0.23, 0.23, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "                       [0.  , 0.  , 0.  , 0.23, 0.23, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "                       [0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "                       [0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.  , 0.  , 0.  ],\n",
    "                       [0.  , 0.23, 0.  , 0.  , 0.  , 0.23, 0.23, 0.  , 0.  , 0.  ],\n",
    "                       [0.23, 0.  , 0.  , 0.  , 0.  , 0.23, 0.23, 0.23, 0.  , 0.  ],\n",
    "                       [0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.23, 0.23, 0.23, 0.  ],\n",
    "                       [0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.23, 0.23, 0.23, 0.23] ])\n",
    "decays = 1.0\n",
    "baseline = np.array([0.01] * len(adjacency))\n",
    "# Compute the ground-truth cumulants\n",
    "L_true, C_true, Kc_true = lib.utils.cumulants.compute_cumulants(G=adjacency, mus=baseline,)\n",
    "\n",
    "\n",
    "def simulate(noise_scale, seed):\n",
    "    \"\"\"Simulate a randomly translated realization of the process\"\"\"\n",
    "    # Define the (noiseless) MHP simulation object\n",
    "    simu_hawkes = SimuHawkesExpKernels(adjacency=adjacency, decays=decays, baseline=baseline, max_jumps=0, verbose=False)\n",
    "    # Define noise distributions\n",
    "    noise_rand_state = np.random.RandomState(seed=None)\n",
    "    noise_dist_arr =  ['gaussian' for _ in range(simu_hawkes.n_nodes)]\n",
    "    noise_scale_arr = [noise_scale for _ in range(simu_hawkes.n_nodes)]\n",
    "    # Build noisy simulation object\n",
    "    simu_noisy_hawkes = lib.simulation.noisy_hawkes.SimulatorNoisyHawkesCustomKernels(\n",
    "        simu_obj=simu_hawkes,\n",
    "        noise_dist=noise_dist_arr,\n",
    "        noise_scale=noise_scale_arr,\n",
    "        burn_in_quantile=0.99,\n",
    "        num_real=1,\n",
    "        num_jumps=100000,\n",
    "        seed=seed,\n",
    "        no_multi=False)\n",
    "    # Simulate data\n",
    "    noisy_events, orig_events = simu_noisy_hawkes.simulate(return_original_events = True)\n",
    "    return noisy_events\n",
    "\n",
    "\n",
    "def get_best_integration_support(events, max_iter=20, initial_simplex=[[10.0], [50.0]], verbose=False):\n",
    "    \"\"\"Hyper-parameter tuning for the bandwidht of the cumulant estimator in NPHC\"\"\"\n",
    "    def int_support_loss(H, events):\n",
    "        nphc = HawkesCumulantMatching(integration_support=float(H), max_iter=0, verbose=False)\n",
    "        nphc.fit(events)\n",
    "        skew_loss = np.linalg.norm(nphc.skewness - Kc_true, ord=2)\n",
    "        cov_loss = np.linalg.norm(nphc.covariance - C_true, ord=2)\n",
    "        norm_sq_K_c = np.linalg.norm(nphc.skewness, ord=2)**2 \n",
    "        norm_sq_C = np.linalg.norm(nphc.covariance, ord=2)**2 \n",
    "        cs_ratio = norm_sq_K_c / (norm_sq_K_c + norm_sq_C)\n",
    "        loss = (1-cs_ratio) * skew_loss + cs_ratio * cov_loss\n",
    "        if verbose:\n",
    "            print(f\"{float(H):>6.2f}, loss={loss:.2e}, skew_loss={skew_loss:.2e}, cov_loss={cov_loss:.2e}\")\n",
    "        return skew_loss\n",
    "    res = scipy.optimize.minimize(\n",
    "        int_support_loss, \n",
    "        x0=20.0, \n",
    "        args=(events,), \n",
    "        options={'max_iter': max_iter, \n",
    "                 'maxfev': max_iter, \n",
    "                 'initial_simplex': initial_simplex}, \n",
    "        method='Nelder-Mead')\n",
    "    return float(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Run the Proof-Of-Concept for a fixed noise scale $\\sigma^2 = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simulate data...')\n",
    "noisy_events = simulate(noise_scale=5.0, seed=534543)\n",
    "print('done.')\n",
    "\n",
    "# ADM4\n",
    "adm4 = HawkesADM4(decay=1.0, verbose=True)\n",
    "adm4.fit(noisy_events)\n",
    "print(\"ADM4: L2-dist: done.\")\n",
    "\n",
    "# WH\n",
    "wh = HawkesConditionalLaw(delta_lag=0.1, min_lag=0.0001, max_lag=100.0,\n",
    "                          n_quad=20, max_support=10.0)\n",
    "wh.fit(noisy_events)\n",
    "wh_adj = wh.get_kernel_norms()\n",
    "print(\"WH: L2-dist: done.\")\n",
    "\n",
    "# NPHC\n",
    "nphc = HawkesCumulantMatching(integration_support=15.0, solver='adam', max_iter=10000, \n",
    "                              penalty='none', verbose=True)\n",
    "nphc.fit(noisy_events)\n",
    "print(\"NPHC: done.\")\n",
    "\n",
    "# Desync-MLE\n",
    "end_time = max([max(map(max, real)) for real in noisy_events])\n",
    "dim = len(baseline)\n",
    "desyncmle = HawkesExpKernConditionalMLE(\n",
    "    decay=1.0,\n",
    "    noise_penalty='l2', noise_C=1e3,\n",
    "    hawkes_penalty='l1', hawkes_base_C=1e2, hawkes_adj_C=1e5,\n",
    "    solver='sgd', tol=1e-4, max_iter=1000,\n",
    "    verbose=False\n",
    ")\n",
    "desyncmle.fit(noisy_events[0], end_time=end_time,\n",
    "            z_start=np.zeros(dim),\n",
    "            theta_start=np.hstack((\n",
    "                0.01*np.ones(dim),\n",
    "                np.random.uniform(0.0, 0.1, size=dim**2)\n",
    "            )),\n",
    "            callback=None)\n",
    "desyncmle_adj = np.reshape(desyncmle.coeffs[2*dim:], (dim, dim))\n",
    "print(\"Desync-MLE: done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lib.utils.plotting.plotmat_sidebyside(\n",
    "    {'(a) Ground-truth': adjacency, \n",
    "     '(b) ADM4': adm4.adjacency,\n",
    "     '(c) Desync-MLE': desyncmle_adj,\n",
    "     '(d) WH': wh_adj,\n",
    "     '(e) NPHC': nphc.adjacency, \n",
    "    }, grid=(1, 5), figsize=(10, 3.25), ytitle=1.0, ticks=[1, 5, 10])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Estimate the excitation matrix for varying noise levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run the simulations\n",
    "\n",
    "Because the experiments are time consuming, there are run in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script_run_synthetic_experiments.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results from the experiment script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('res-synthetic.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_queries = [\n",
    "    ('adm4', 'ADM4'),\n",
    "    ('nphc', 'NPHC'),\n",
    "    ('wh',   'WH'),\n",
    "    ('desyncmle', 'Desync-MLE'),\n",
    "]\n",
    "\n",
    "metric_queries = [\n",
    "    ('norm',     'Norm',           lambda y_test, y_true: np.linalg.norm(y_test.ravel(), ord=2)**2                             ),\n",
    "    ('relerr',   'Relative Error', lambda y_test, y_true: lib.utils.metrics.relerr(y_test, y_true, null_norm='min')       ),\n",
    "    ('precAt5',  'Precison@5',     lambda y_test, y_true: lib.utils.metrics.precision_at_n(y_test.ravel(), y_true.ravel(), n=5)           ),\n",
    "    ('precAt10', 'Precison@10',    lambda y_test, y_true: lib.utils.metrics.precision_at_n(y_test.ravel(), y_true.ravel(), n=10)          ),\n",
    "    ('precAt20', 'Precison@20',    lambda y_test, y_true: lib.utils.metrics.precision_at_n(y_test.ravel(), y_true.ravel(), n=20)          ),\n",
    "    ('pr-auc',   'PR-AUC',         lambda y_test, y_true: lib.utils.metrics.pr_auc_score(y_test.ravel(), y_true.ravel())                  ),\n",
    "]\n",
    "\n",
    "for method, _ in method_queries:\n",
    "    for suffix, _, func in metric_queries:\n",
    "        df[f'{method}_{suffix}'] = df[f'{method}_adj'].apply(lambda adj: func(y_test=adj, y_true=adjacency))\n",
    "        \n",
    "df['cov_l2'] = df['cov'].apply(lambda val: np.linalg.norm(C_true.T - val, ord=2))\n",
    "df['skew_l2'] = df['skew'].apply(lambda val: np.linalg.norm(Kc_true.T - val, ord=2))\n",
    "\n",
    "df_plot = df.groupby('noise_scale').agg(['mean', 'std', 'count'])\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Plot the Cumulant Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.75, 6.75 * 2/3))\n",
    "plt.errorbar(df_plot.index, \n",
    "             df_plot.cov_l2['mean'],\n",
    "             yerr=df_plot.cov_l2['std']/np.sqrt(df_plot.cov_l2['count']), \n",
    "             label=r'$2^{\\mathrm{nd}}$-order cumulants (Covariance)')\n",
    "plt.errorbar(df_plot.index, \n",
    "             df_plot.skew_l2['mean'],\n",
    "             yerr=df_plot.skew_l2['std']/np.sqrt(df_plot.skew_l2['count']), \n",
    "             label=r'$3^{\\mathrm{rd}}$-order cumulants(Skewness)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'Noise scale $\\sigma^2$')\n",
    "plt.ylabel(('Average L2-distance to\\n'\n",
    "            'ground-truth cumulants\\n'));\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(top=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Plot the Estimation Performance w.r.t. Varying Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix, metric_label, _ in metric_queries:    \n",
    "    print(metric_label, flush=True)\n",
    "    plt.figure(figsize=(6.75/4, 3.25*0.5*0.85))\n",
    "    plt.grid()\n",
    "    for method, method_label in method_queries:\n",
    "        yseries = df_plot[f'{method}_{suffix}']\n",
    "        y = yseries['mean']\n",
    "        #yerr = yseries['std']\n",
    "        yerr = yseries['std'] / np.sqrt(yseries['count'])\n",
    "        plt.errorbar(df_plot.index, y, yerr=yerr, label=method_label, )\n",
    "    if suffix.startswith('relerr'):\n",
    "        # plt.legend();\n",
    "        pass\n",
    "    if suffix.startswith('prec'):\n",
    "        plt.legend();\n",
    "        pass\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(f'Noise scale $\\sigma^2$')\n",
    "    plt.ylabel(metric_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
